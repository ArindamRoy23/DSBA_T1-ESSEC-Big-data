{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9de140af",
   "metadata": {},
   "source": [
    "# <font color=darkred> IDSS32102</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "704eea9e",
   "metadata": {},
   "source": [
    "<h1><center> Sparse Implementation of LSH</center></h1>\n",
    "\n",
    "Locality Sensitive Hashing (LSH) can be implemented for both sparse and dense vectors. In this notebook we will implement the algorithm for searching sparse vectors. We will be using k-shingling and minhashing to create our sparse vectors before applying them for search with LSH.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85bce9ec",
   "metadata": {},
   "source": [
    "# k-shingling:\n",
    "\n",
    "We start by defining a few sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ada9a771",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = \"flying bird found in the space\"\n",
    "b = \"he will not allow you to bring your sticks of dynamite and pet armadillo along\"\n",
    "c = \"he figured a few sticks of dynamite were easier than a fishing pole to catch an armadillo\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be2df312",
   "metadata": {},
   "source": [
    "The first thing we do is create our shingles, we will use k-shingles where k == 2. For longer text it is recommended to create shingles where it is unlikely to produce matching shingles between non-matching text, k values of 7 to 11 would likely produce this outcome.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "549aabb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fl|ly|yi|in|ng|g | b|bi|ir|rd|d | f|fo|ou|un|nd|d | i|in|n | t|th|he|e | s|sp|pa|ac|ce|"
     ]
    }
   ],
   "source": [
    "k = 2\n",
    "for i in range(len(a) - k+1):\n",
    "    print(a[i: i+k], end='|')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1204bb60",
   "metadata": {},
   "source": [
    "These are our shingles, however, we must remove duplicate values as we are producing a set. We do this using the Python type set. \n",
    "\n",
    "1) Define a shingle function to apply shingling to each of our sentences:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "1a9344d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def shingle(text: str, k: int):\n",
    "    shingle_set = []\n",
    "    for i in range(len(text) - k+1):\n",
    "        print(text[i: i+k], end='|')\n",
    "    return set(shingle_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "77e77b55",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = shingle(a, k)\n",
    "b = shingle(b, k)\n",
    "c = shingle(c, k)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a887bff",
   "metadata": {},
   "source": [
    "Now that we have our three shingles we create a shingle vocabulary by create a union between all three sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "id": "0702837e",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = list(a.union(b).union(c))\n",
    "print(vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f1b0c18",
   "metadata": {},
   "source": [
    "Using this vocab we can create one-hot encoded sparse vectors to represent our shingles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "id": "5b327913",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_1hot = [1 if x in a else 0 for x in vocab]\n",
    "b_1hot = [1 if x in b else 0 for x in vocab]\n",
    "c_1hot = [1 if x in c else 0 for x in vocab]\n",
    "print(a_1hot)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fcd187c",
   "metadata": {},
   "source": [
    "So we now have one-hot encoded sparse vectors we can move onto minhashing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcb15d03",
   "metadata": {},
   "source": [
    "# Minhashing\n",
    "\n",
    "Minhashing is the next step in our process. After creating our shingle sets we use minhashing to create signatures from those sets.\n",
    "\n",
    "To create our minhashing function we build several hash functions, each will randomly count from 1 to len(vocab) + 1 - creating a random vector:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "id": "da4f0e44",
   "metadata": {},
   "outputs": [],
   "source": [
    "hash_ex = list(range(1, len(vocab)+1))\n",
    "print(hash_ex)  # we haven't shuffled yet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "3723fcc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import shuffle\n",
    "\n",
    "shuffle(hash_ex)\n",
    "print(hash_ex)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35d7d901",
   "metadata": {},
   "source": [
    "We now have a randomized list of integers which we can use in creating our hashed signatures. What we do now is begin counting from 1 through to len(vocab) + 1, extracting the position of this number in our new hash_ex list, like so (for the first few integers):\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "id": "a51a6ec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1, 5):\n",
    "    print(f\"{i} -> {hash_ex.index(i)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03249f75",
   "metadata": {},
   "source": [
    "\n",
    "What we do with this is count up from 1 to len(vocab) + 1 and find if the resultant hash_ex.index(i) position in our one-hot encoded vectors contains a positive value (1) in that position, like so:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "id": "52bd9549",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1, len(vocab)+1):\n",
    "    idx = hash_ex.index(i)\n",
    "    signature_val = a_1hot[idx]\n",
    "    print(f\"{i} -> {idx} -> {signature_val}\")\n",
    "    if signature_val == 1:\n",
    "        print('match!')\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49300b8a",
   "metadata": {},
   "source": [
    "That gives us a first signature of some value. But this is just a single value, and it takes many values to create a signature (100 for example).\n",
    "\n",
    "So, how to we generate these other values? By using more hash functions! Let's generate a set of hash functions to create a signature vector of length 20.\n",
    "\n",
    "hash_funcs = []\n",
    "\n",
    "for _ in range(20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "id": "d34d4b4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "hash_funcs = []\n",
    "\n",
    "for _ in range(20):\n",
    "    hash_ex = list(range(1, len(vocab)+1))\n",
    "    shuffle(hash_ex)\n",
    "    hash_funcs.append(hash_ex)\n",
    "\n",
    "for i in range(3):\n",
    "    print(f\"hash function {i+1}:\")\n",
    "    print(hash_funcs[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5d2a1b5",
   "metadata": {},
   "source": [
    "We're only showing the first three hash functions here - we have 20 in total. To create our signatures we simply process each one-hot vector through each hash function, appending the output value to our signature for that vector.\n",
    "\n",
    "2) Complete the following signature code:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "id": "755b47fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "signature = []\n",
    "\n",
    "for func in hash_funcs:\n",
    "    for i in range(1, len(vocab)+1):\n",
    "        idx = func.index(i)\n",
    "        signature_val = a_1hot[idx]\n",
    "        # ...\n",
    "\n",
    "#print(signature)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bbaed1a",
   "metadata": {},
   "source": [
    "And there we have our minhash produced signature for a. Let's clean up the code and formalize the process a little.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "a38cf342",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_hash_func(size: int):\n",
    "    # function for creating the hash vector/function\n",
    "    hash_ex = list(range(1, size+1))\n",
    "    shuffle(hash_ex)\n",
    "    return hash_ex\n",
    "\n",
    "def build_minhash_func(vocab_size: int, nbits: int):\n",
    "    # function for building multiple minhash vectors\n",
    "    hashes = []\n",
    "    for _ in range(nbits):\n",
    "        hashes.append(create_hash_func(vocab_size))\n",
    "    return hashes\n",
    "\n",
    "# we create 20 minhash vectors\n",
    "minhash_func = build_minhash_func(len(vocab), 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba4cfa5a",
   "metadata": {},
   "source": [
    "3) Write a signature function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "id": "19c37f67",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_hash(vector: list):\n",
    "    # use this function for creating our signatures (eg the matching)\n",
    "    return signature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "1e86763e",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_sig = create_hash(a_1hot)\n",
    "b_sig = create_hash(b_1hot)\n",
    "c_sig = create_hash(c_1hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "id": "8df53a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(a_sig)\n",
    "#print(b_sig)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77a9fde4",
   "metadata": {},
   "source": [
    "We now have our three minhashed signatures! These signatures, despite being seemingly randomized, will on average have the very similar Jaccard similarity values as our previous sparse vectors. We have reduced the dimensionality of our vectors significantly - but maintained the same information!\n",
    "\n",
    "4) Write a Jaccard similarity function:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "id": "e2f13015",
   "metadata": {},
   "outputs": [],
   "source": [
    "def jaccard(a: set, b: set):\n",
    "    return #...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a816c2e",
   "metadata": {},
   "source": [
    "a should have lower similarity with b and c:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "id": "cc9205e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "jaccard(a, b), jaccard(set(a_sig), set(b_sig))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "id": "242535d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "jaccard(a, c), jaccard(set(a_sig), set(c_sig))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "id": "0506238c",
   "metadata": {},
   "outputs": [],
   "source": [
    "jaccard(b, c), jaccard(set(b_sig), set(c_sig))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be210ee6",
   "metadata": {},
   "source": [
    "We're now ready to move onto the LSH process.\n",
    "\n",
    "## Locality Sensitive Hashing\n",
    "\n",
    "The approach we will be taking in this notebook is break our signature vector into multiple bands, creating several sub-vectors.\n",
    "\n",
    "We then hash each of these sub-vectors into a set of buckets, if we find that two sub-vectors from two signature vectors collide (end up in the same hash bucket) we take the two full signature vectors as candidate pairs - which we then compare in full with a similarity metric (like Jaccard similarity, cosine similarity, etc).\n",
    "\n",
    "There is no 'set' way to hash our signature vectors, and in-fact the simplest approach is to check for equivalence across sub-vectors, which will be our approach.\n",
    "\n",
    "First, we must define the number of buckets b we would like to create. It's important to note that each bucket must contain an equal number of rows r - and so our signature length must be divisible by b.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "f7b16507",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_vector(signature, b):\n",
    "    assert len(signature) % b == 0\n",
    "    r = int(len(signature) / b)\n",
    "    # code splitting signature in b parts\n",
    "    subvecs = []\n",
    "    for i in range(0, len(signature), r):\n",
    "        subvecs.append(signature[i : i+r])\n",
    "    return subvecs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93d30090",
   "metadata": {},
   "source": [
    "We'll start by splitting into 10 bands, creating rows of 2 - on the small side to be used in a genuine LSH function but good for our example (we'll explore different r and b values soon).\n",
    "\n",
    "Let's start with our b and c vectors, which should hopefully match in at least one band."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "id": "433e6b30",
   "metadata": {},
   "outputs": [],
   "source": [
    "band_b = split_vector(b_sig, 10)\n",
    "band_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "id": "ff3c3b6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "band_c = split_vector(c_sig, 10)\n",
    "band_c"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5057ee4",
   "metadata": {},
   "source": [
    "Check if they match (we'll rewrite some of this into Numpy soon)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "id": "8781597a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for b_rows, c_rows in zip(band_b, band_c):\n",
    "    if b_rows == c_rows:\n",
    "        print(f\"Candidate pair: {b_rows} == {c_rows}\")\n",
    "        # we only need one band to match\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53500ee0",
   "metadata": {},
   "source": [
    "And let's do the same for a."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "e01f01b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "band_a = split_vector(a_sig, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "9f867ec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for a_rows, b_rows in zip(band_a, band_b):\n",
    "    if a_rows == b_rows:\n",
    "        print(f\"Candidate pair: {a_rows} == {b_rows}\")\n",
    "        # we only need one band to match\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "bb7d5020",
   "metadata": {},
   "outputs": [],
   "source": [
    "for a_rows, c_rows in zip(band_a, band_c):\n",
    "    if a_rows == c_rows:\n",
    "        print(f\"Candidate pair: {a_rows} == {c_rows}\")\n",
    "        # we only need one band to match\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa160963",
   "metadata": {},
   "source": [
    "Okay great, so even with this very simple implementation - we most likely managed to identify sentences b and c as candidate pairs, and identify a as a non-candidate.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46f7dff9",
   "metadata": {},
   "source": [
    "## Tuning LSH\n",
    "\n",
    "We can visualize the probability of returning a candidate pair vs the similarity of the pair for different values of r and b (rows and bands respectively) like so:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "36346f2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def probability(s, r, b):\n",
    "    # s: similarity\n",
    "    # r: rows (per band)\n",
    "    # b: number of bands\n",
    "    return 1 - (1 - s**r)**b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "66f074c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "09245de6",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame({\n",
    "    's': [],\n",
    "    'P': [],\n",
    "    'r,b': []\n",
    "})\n",
    "\n",
    "for s in np.arange(0.01, 1, 0.01):\n",
    "    total = 100\n",
    "    for b in [100, 50, 25, 20, 10, 5, 4, 2, 1]:\n",
    "        r = int(total/b)\n",
    "        P = probability(s, r, b)\n",
    "        results = results.append({\n",
    "            's': s,\n",
    "            'P': P,\n",
    "            'r,b': f\"{r},{b}\"\n",
    "        }, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "id": "1f588f88",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lineplot(data=results, x='s', y='P', hue='r,b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4860706f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
